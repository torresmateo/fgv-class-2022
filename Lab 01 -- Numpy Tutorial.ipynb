{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "armed-armenia",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NumPy/SciPy Tutorial\n",
    "\n",
    "In this lab session, we'll go through [NumPy](https://numpy.org/). When you complete this notebook, you'll have a better understanding of most of the use cases that you'll need througout the course.\n",
    "\n",
    "* this is a self-paced tutorial, but make sure you take some time on this week to get familiar with it. \n",
    "* If you find any part of this tutorial complicated, please prepare a list of questions for the beginning of the next lab. \n",
    "* I am aware that this may seem obvious and boring, but the answer to any question is probably contained in the [NumPy User Guide](https://numpy.org/doc/stable/user/index.html) and [Documentation](https://numpy.org/doc/stable/). \n",
    "* If you're serious about data science in Python, I strongly suggest going through the [NumPy Fundamentals](https://numpy.org/doc/stable/user/basics.html#numpy-fundamentals) at least once in your career. In fact, this very tutorial is mostly a condensed version of the Numpy fundamentals plus some SciPy, links to the relevant documentation pages are provided everywhere in the tutorial if you feel like having a deep dive into NumPy.\n",
    "\n",
    "## Table of contents:\n",
    "\n",
    "1. [The ndarray object](#The-ndarray-object)\n",
    "2. [Array indexing](#Array-indexing)\n",
    "3. [Broadcasting](#Broadcasting)\n",
    "4. [Random number generators](#Random-number-generators)\n",
    "5. [Copies and Views](#Copies-and-Views)\n",
    "6. [Data Types](#Data-Types)\n",
    "\n",
    "Before we start, let's import the libraries we'll need throughout the course, as well as some utility functions that will help us visualize what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if you're using Google Colab\n",
    "\n",
    "!git clone https://github.com/torresmateo/fgv-class-2022.git\n",
    "!cp -r fgv-class-2022/images .\n",
    "!cp -r fgv-class-2022/tutorials ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-earth",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tutorials.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-advertising",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The ndarray object\n",
    "\n",
    "In this section we will interact with (arguably) the most popular data structure in data science. The [Numpy ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-korean",
   "metadata": {},
   "source": [
    "### Creating a new array\n",
    "\n",
    "The most intuitive way to create a numpy array is from an existing Python list or tuple. We do this by calling [`np.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html) and passing a list to the function. The parameter can be any \"array-like\" object in python. To understand what is and isn't \"array-like\", check the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-receiver",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-rainbow",
   "metadata": {},
   "source": [
    "Numpy also provides functions for intrinsic array creation. Here we look at some options that will be very useful throughout the course, but there are many more. The first group is to create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-apartment",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.empty(5) # array of uninitialized data\n",
    "print(f\"np.empty: {a}\")\n",
    "\n",
    "a = np.zeros(5) # array initialized with zeros\n",
    "print(f\"np.zeros: {a}\")\n",
    "\n",
    "a = np.arange(5) # array initialized with zeros\n",
    "print(f\"np.arange: {a}\")\n",
    "\n",
    "a = np.eye(5, 8) # array with ones in the \"main\" diagonal\n",
    "print(f\"np.eye:\\n{a}\")\n",
    "\n",
    "a = np.identity(5) # array with ones in the main diagonal\n",
    "print(f\"np.identity:\\n{a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-female",
   "metadata": {},
   "source": [
    "We can also create an array from existing arrays:\n",
    "\n",
    "Let's start with 2 arrays created from lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-basin",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "b = np.arange(10, 20)\n",
    "\n",
    "c = np.vstack([a, b])\n",
    "print(f\"np.vstack:\\n{c}\")\n",
    "\n",
    "d = np.hstack([a, b])\n",
    "print(f\"np.hstack:\\n{d}\")\n",
    "\n",
    "e = np.array(a, ndmin=3)\n",
    "print(f\"np.array with ndim=3:\\n{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-helen",
   "metadata": {},
   "source": [
    "Finally, we can mutate existing arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-arizona",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_t = c.transpose()\n",
    "print(f\"c.transpose():\\n{c_t}\")\n",
    "\n",
    "D = np.diag(a)\n",
    "print(f\"np.diag(a):\\n{D}\")\n",
    "\n",
    "f = np.diag(D)\n",
    "print(f\"np.diag(D):\\n{f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-death",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Array attributes and methods\n",
    "\n",
    "\n",
    "The ndarray data structure has some convenient attributes and methods we can use to interact with this array in a way that is way more convenient, safer, and faster than implementing our own structure. For example, we use the `shape` atrribute to get the cardinality of each dimension of the array, the `ndim` attribute to tell how many dimensions the array has, and the `T` attribute to get a transposed version of the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-union",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"shape: {a.shape}\")\n",
    "print(f\"ndim: {a.ndim}\")\n",
    "print(f\"T:\\n{c.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-gentleman",
   "metadata": {},
   "source": [
    "**IMPORTANT: unidimensional vectors in numpy**\n",
    "\n",
    "Notice how the shape of the array is `(10,)`. This means that the array is \n",
    "not a column nor a row vector. This can have some complications when dealing with vector operations. For standard vector algebra, we need to explicitly create a 2D array.\n",
    "\n",
    "numpy's `dot` and `matmul` (or `@` operator) will work with unidimensional arrays by appending or prepending a dimension to the arguments. Let's see some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-semiconductor",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weirdness of unidimensional arrays:\n",
    "\n",
    "print(f\"np.array_equal(a, a.T): {np.array_equal(a, a.T)}\")\n",
    "print(f\"np.matmul(a, a.T): {np.matmul(a, a.T)}\")\n",
    "print(f\"np.matmul(a.T, a): {np.matmul(a.T, a)}\")\n",
    "print(f\"np.matmul(a, a): {np.matmul(a, a)}\")\n",
    "\n",
    "# we transform the unidimensional array into a 2D array by adding a new,\n",
    "# empty dimension\n",
    "a_2d = a[:, np.newaxis]\n",
    "\n",
    "print(\"\\n2D array\\n\")\n",
    "\n",
    "print(f\"a_2d.shape: {a_2d.shape}\")\n",
    "print(f\"np.array_equal(a_2d, a_2d.T): {np.array_equal(a_2d, a_2d.T)}\")\n",
    "print(f\"np.matmul(a_2d, a_2d.T):\\n{np.matmul(a_2d, a_2d.T)}\")\n",
    "print(f\"np.matmul(a_2d.T, a_2d): {np.matmul(a_2d.T, a_2d)}\")\n",
    "\n",
    "# this one will generate an error, \n",
    "# but you're encouraged to uncomment and try\n",
    "# print(f\"np.matmul(a_2d, a_2d): {np.matmul(a_2d, a_2d)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-denmark",
   "metadata": {},
   "source": [
    "Other useful methods are aggregations and indices identifiers, here are a couple of useful examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-kidney",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's start with a new, unsorted array\n",
    "a = np.array([2,6,3,8,9,1,5,7,3])\n",
    "print(f\"original array: {a}\")\n",
    "\n",
    "# get the maximum element\n",
    "print(f\"a.max(): {a.max()}\")\n",
    "\n",
    "# get the index of the maximum element\n",
    "print(f\"a.argmax(): {a.argmax()}\")\n",
    "\n",
    "# get the maximum element\n",
    "print(f\"a.min(): {a.min()}\")\n",
    "\n",
    "# get the index of the maximum element\n",
    "print(f\"a.argmin(): {a.argmin()}\")\n",
    "\n",
    "# get the mean of all values\n",
    "print(f\"a.mean(): {a.mean()}\")\n",
    "\n",
    "# get the sum of all values\n",
    "print(f\"a.sum(): {a.sum()}\")\n",
    "\n",
    "# get the indices that would sort the array\n",
    "print(f\"a.argsort(): {a.argsort()}\")\n",
    "print(f\"a[a.argsort()]: {a[a.argsort()]}\")\n",
    "\n",
    "# get a 2D array with the data from the array\n",
    "print(f\"a.reshape(3,3):\\n{a.reshape(3,3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-audio",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Array indexing\n",
    "\n",
    "Array indexing in numpy is compatible with the standard Python `my_array[my_selection]` syntax, but allows for more complex indexing and slicing operations in higher dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-standing",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Basic indexing\n",
    "\n",
    "If you've programmed using Python lists before, this way of indexing will feel very natural to you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-physics",
   "metadata": {},
   "source": [
    "#### Single element indexing\n",
    "\n",
    "To get a single element from a unidimensional ndarray, you use the exact same syntax as getting single elements from Python lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-optics",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"original array: {a}\")\n",
    "\n",
    "# get the first element\n",
    "print(f\"first element: {a[0]}\")\n",
    "\n",
    "# get the last element\n",
    "print(f\"last element: {a[-1]}\")\n",
    "\n",
    "# get the second to last element\n",
    "print(f\"second to last element: {a[-2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-distributor",
   "metadata": {},
   "source": [
    "for 2D arrays, we can use the \"list of lists\" way of indexing, but the \"numpy way\" is to use a tuple, where each element of the tuple indexes a dimension: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-memory",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_2d = a.reshape(3, 3)\n",
    "print(f\"2D array:\\n{a_2d}\")\n",
    "\n",
    "# these two notations are equivalent, but the latter is preferred,\n",
    "# especially for higher dimensional arrays\n",
    "print(f\"a_2d[1][1]: {a_2d[1][1]}, a_2d[1, 1]: {a_2d[1,1]}\")\n",
    "\n",
    "# of course, you can use negative indexing to start from the end of each\n",
    "# dimension\n",
    "print(f\"a_2d[1, -1]: {a_2d[1,-1]}\")\n",
    "\n",
    "# Get the first row (as a unidimensional array)\n",
    "print(f\"first row (1D): {a_2d[0]}\")\n",
    "\n",
    "# Get the last column (as a unidimensional array)\n",
    "# the : in the first dimension means \"all elements\" of that dimension\n",
    "print(f\"last column (1D): {a_2d[:,-1]}\")\n",
    "\n",
    "# Get the first row (as a unidimensional array)\n",
    "print(f\"first row (2D): {a_2d[[0]]}\")\n",
    "\n",
    "# Get the last column (as a unidimensional array)\n",
    "# the : in the first dimension means \"all elements\" of that dimension\n",
    "print(f\"last column (2D):\\n{a_2d[:,[-1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-winning",
   "metadata": {},
   "source": [
    "#### Slicing and striding\n",
    "\n",
    "Slicing in NumPy is also compatible and extends Python's basic concept of slicing to N dimensions. In this tutorial, we're going to work with unidimensional and 2-dimensional arrays, but I strongly encourage you to get familiar with array manipulation in higher dimensions, especially 3-dimensional arrays (often used for colored images), and 4-dimensional arrays (a \"batch\" of colored images). \n",
    "\n",
    "The basic slice is `start:stop:step`. This selects the elements in the array with indices corresponding to `start`, `start + step`, `start + 2 * step`, `...`, `start + m * steps`, where `m` is the maximum integer value of `m` so that `start + m * steps < stop`. By default, `start = 0`, `stop = None`, and `step = 1`.\n",
    "\n",
    "Below we have some common useful examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-margin",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's start with a sorted array, where every value matches its index\n",
    "a = np.arange(10)\n",
    "\n",
    "# select every element with an even index\n",
    "print(f\"every element with an even index: {a[::2]}\")\n",
    "\n",
    "# select every element with an odd index\n",
    "print(f\"every element with an odd index: {a[1::2]}\")\n",
    "\n",
    "# reverse the array \n",
    "print(f\"reversed array: {a[::-1]}\")\n",
    "\n",
    "# let's create a bigger 2d array\n",
    "b = np.arange(25).reshape(5, 5)\n",
    "\n",
    "print(f\"original 2D array:\\n{b}\")\n",
    "\n",
    "# get every even row, and all columns\n",
    "print(f\"even rows:\\n{b[::2,:]}\")\n",
    "\n",
    "# get all rows, and every odd column\n",
    "print(f\"odd columns:\\n{b[:,1::2]}\")\n",
    "\n",
    "# get center square\n",
    "print(f\"center square:\\n{b[1:4,1:4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-judge",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Advanced indexing\n",
    "\n",
    "On top of the Python slicing, we can use more complex selection objects for indexing. Getting used to all the variants of advanced indexing takes a lot of practice, and it's always useful to have the documentation open in a browser tab nearby.\n",
    "\n",
    "Here I will simply write some examples that I think will be useful during the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-seafood",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's start with a fresh array\n",
    "a = np.arange(10, 0, -1)\n",
    "print(f\"unidimensional array: {a}\")\n",
    "\n",
    "# we can use an ndarray of integers to make a complex selection of indices, and even repeat the indices:\n",
    "print(f\"integer ndarray: {a[np.array([3, 3, 1, 1, -8, 0])]}\")\n",
    "\n",
    "print(f\"integer array: {a[[3, 3, 1, 1, -8, 0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-mortgage",
   "metadata": {},
   "source": [
    "#### Multidimensional indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-miniature",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's start with a fresh 2-dimensional array\n",
    "a = np.arange(25).reshape(5,5)\n",
    "print(f\"2-dimensional array:\\n{a}\")\n",
    "\n",
    "# let's get the elements at specific coordinates\n",
    "# we simply pass an integer list of the components\n",
    "# to each dimension, so, for elements with coordinates:\n",
    "#     (0, 0)\n",
    "#     (1, 4)\n",
    "#     (1, 2)\n",
    "#     (3, 0)\n",
    "print(f\"elements at specific coordinates: {a[[0, 1, 1, 3], [0, 4, 2, 0]]}\")\n",
    "\n",
    "# if all the elements share the same index along one dimension, we can mix\n",
    "# advanced and simple indexing, so for element with coordinates:\n",
    "#     (0, 1)\n",
    "#     (1, 1)\n",
    "#     (1, 1)\n",
    "#     (3, 1)\n",
    "print(f\"elements at specific rows, same column: {a[[0, 1, 1, 3], 1]}\")\n",
    "\n",
    "# get the corner elements \n",
    "# this example uses broadcasting, which will be explained in a section below\n",
    "# but notice how the we use a 2D column vector to indicate the rows, and \n",
    "# a unidimensional vector to indicate the columns\n",
    "rows = np.array([0, -1]) # first and last\n",
    "columns = np.array([0, -1]) # first and last\n",
    "print(f\"corner elements:\\n{a[rows[:, np.newaxis], columns]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-arlington",
   "metadata": {},
   "source": [
    "#### Boolean indexing\n",
    "\n",
    "One of the most useful ways to index a multidimensional array is the boolean index. It allows us to select elements that hold true when subject to a condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-referral",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's keep the same array from the previous example:\n",
    "print(f\"2-dimensional array:\\n{a}\")\n",
    "\n",
    "# let's get all elements that are below 7\n",
    "idx = a < 7\n",
    "print(f\"indices below 7:\\n{idx}\")\n",
    "\n",
    "print(f\"elements below 7:\\n{a[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-productivity",
   "metadata": {},
   "source": [
    "To demonstrate how useful boolean indexes are, let's look at a practical example:\n",
    "\n",
    "We have the image of a dog with a white background. \n",
    "\n",
    "Let's pretend that we need to save some space in our hard-drive, and \n",
    "we want to keep only the relevant part of this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-wrong",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's load the image of a dog in grayscale\n",
    "dog = get_dog_image()\n",
    "\n",
    "# the representation of this image is, in fact, \n",
    "# a 2-dimensional ndarray of integers\n",
    "dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-relief",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's plot the image, just to see what we're dealing with\n",
    "plot_image(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-store",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you look closely to the values in the array, we can see that \n",
    "# the higher the value, the whiter the pixel. \n",
    "# We can use this fact to figure out the silhouette of the dog:\n",
    "\n",
    "white_pixels = dog > 250\n",
    "\n",
    "# we can print the mask to see if we're right\n",
    "plot_image(white_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-expense",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we have a clear idea of where the dog is, \n",
    "# we can select just the rectangle that contains a part of the silhouette\n",
    "\n",
    "# we can achieve this using boolean conditions again.\n",
    "\n",
    "# our mask now has True where the pixel represents the background, \n",
    "# and false if the image represents the dog. This is counterintuitive, \n",
    "# we can flip this aroun\n",
    "\n",
    "silhoutette = ~white_pixels\n",
    "\n",
    "plot_image(silhoutette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-denmark",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now, we want to keep only the rows and columns where at least one pixel \n",
    "# contributes to the silhouette.\n",
    "\n",
    "rows = silhoutette.any(axis=1)\n",
    "cols = silhoutette.any(axis=0)\n",
    "\n",
    "cropped_dog = dog[rows][:, cols]\n",
    "plot_image(cropped_dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-north",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Broadcasting\n",
    "\n",
    "Broadcasting describes how NumPy treats arrays with different shapes during some operations.\n",
    "\n",
    "Normally, operators in NumPy work in an element-wise fashion, which requires that the dimensionality of the operands to be the same. This limitation is removed when the operands have \"broadcastable\" shapes. \n",
    "\n",
    "The simplest form of broadcasting is multiplying a scalar by a unidimensional array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-pottery",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "print(f\"a: {a}\")\n",
    "\n",
    "b = 5\n",
    "print(f\"b: {a}\")\n",
    "\n",
    "print(f\"a * b: {a * b}\")\n",
    "\n",
    "c = np.full_like(a, b)\n",
    "print(f\"array full of scalar c: {c}\")\n",
    "\n",
    "print(f\"a * c: {a * c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-teddy",
   "metadata": {},
   "source": [
    "In the example above, we did not need to manually repeat the scalar to multiply it. NumPy takes care of such expansion under the hood.\n",
    "\n",
    "Let's see a less trivial example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-aerospace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.arange(25).reshape(5,5)\n",
    "print(f\"a:\\n{a}\")\n",
    "\n",
    "b = np.arange(5)\n",
    "print(f\"b:\\n{b}\")\n",
    "\n",
    "print(f\"a + b:\\n{a + b}\")\n",
    "\n",
    "c = b[:, np.newaxis]\n",
    "\n",
    "print(f\"c:\\n{c}\")\n",
    "\n",
    "print(f\"a + c:\\n{a + c}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-cologne",
   "metadata": {},
   "source": [
    "In the example above, we summed a unidimensional array, which was broadcast along the rows of the 2-dimensional array, and for each row, the element-wise sum was performed.\n",
    "\n",
    "Then, we added a new dimension to the smaller array, and turned into a column vector, that was broadcasted over the columns of the bigger array.\n",
    "\n",
    "Let's look at an example where both arrays will be broadcast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-schedule",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-issue",
   "metadata": {},
   "source": [
    "In this example, we're summing a unidimensional `(5,)` vector with a column `(1, 5)` vector, resulting in a `(5,5)` matrix that is the outer product of the 2 vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-acrobat",
   "metadata": {},
   "source": [
    "## Random number generators\n",
    "\n",
    "In the [array creation](#Creating-a-new-array) section above, we saw an example of how to create an uninitialized array with `np.empty`. While this might seem enough to create a random array for rapid prototyping, this is note quite true.\n",
    "\n",
    "In most cases when we deal with random number generators, some level of control is useful and often necessary to achieve repeatable results.\n",
    "\n",
    "This matter is so important that a massive effort was put into creating [`numpy.random`](https://numpy.org/doc/stable/reference/random/index.html): the NumPy module of random number routines.\n",
    "\n",
    "Below some useful examples using the new Random Generator API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-perfume",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we import the default random number generator\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-mexico",
   "metadata": {},
   "source": [
    "by default, this uses a fresh unpredictable seed. Run this cell many times and you will generate a different set of mnatrices every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-dakota",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "rng = default_rng() \n",
    "\n",
    "a = rng.random((5,5))\n",
    "b = rng.random((5,5))\n",
    "c = rng.random((5,5))\n",
    "print(f\"a:\\n{a}\")\n",
    "print(f\"b:\\n{b}\")\n",
    "print(f\"c:\\n{c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-thanksgiving",
   "metadata": {},
   "source": [
    "If we sed a known seed, we can make sure we're using the same data.\n",
    "This is extremely usfeul for prototyping!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-queen",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = default_rng(0) \n",
    "\n",
    "a = rng.random((5,5))\n",
    "b = rng.random((5,5))\n",
    "c = rng.random((5,5))\n",
    "print(f\"a:\\n{a}\")\n",
    "print(f\"b:\\n{b}\")\n",
    "print(f\"c:\\n{c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-persian",
   "metadata": {},
   "source": [
    "Among the most useful tools is to draw sample from a known distribution. Extremely useful to generate test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-constant",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample some data from the normal distribution\n",
    "rng = default_rng(0)\n",
    "\n",
    "a = rng.normal(size=10000)\n",
    "plot_distribution(a, title=\"Normal distribution\")\n",
    "\n",
    "a = rng.power(50, size=10000)\n",
    "plot_distribution(a, title=\"Power distribution\")\n",
    "\n",
    "a = rng.uniform(size=10000)\n",
    "plot_distribution(a, title=\"Uniform distribution\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-thumbnail",
   "metadata": {},
   "source": [
    "## Copies and Views\n",
    "\n",
    "The ndarray is ultimately a data structure, and it consists mainly of two parts: \n",
    "* a data buffer with the actual elements of the array\n",
    "* metadata that contains information about the data buffer, such as the data type, strides, and all the information necessary to manipulate the array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-emperor",
   "metadata": {},
   "source": [
    "### Views\n",
    "\n",
    "Many NumPy operations can be achieved by simply modifying some of the metadata, but using the same underlying data buffer. This can save memory and ensures good performance, but it is important to be aware that we're not dealing with a copy of the values to avoid bugs. \n",
    "\n",
    "Let's test this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-radical",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "print(f\"a: {a}\")\n",
    "\n",
    "b = a[:5]\n",
    "print(f\"b: {b}\")\n",
    "\n",
    "print(f\"\\nsetting b[0] = 25\")\n",
    "b[0] = 25\n",
    "\n",
    "print(f\"b: {b}\")\n",
    "print(f\"a: {a}\")\n",
    "\n",
    "print(f\"\\nsetting a[1] = 25\")\n",
    "b[1] = 25\n",
    "\n",
    "print(f\"a: {a}\")\n",
    "print(f\"b: {b}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-nomination",
   "metadata": {},
   "source": [
    "We can see that the two arrays are somehow \"linked\" together, because changing one affects the other one. This is because `b` is a view of the original array `a`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-tenant",
   "metadata": {},
   "source": [
    "### Copies\n",
    "\n",
    "As the name suggest, when we create a copy, we are not only creating some new metadata for the same data buffer, but we're actually making a copy of the entire buffer, and the two variables will not be conneced.\n",
    "\n",
    "Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-dictionary",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.arange(16).reshape(4,4)\n",
    "\n",
    "print(f\"a:\\n{a}\")\n",
    "\n",
    "# adding a value to every element forces a copy\n",
    "b = a + 1 \n",
    "\n",
    "print(f\"b:\\n{b}\")\n",
    "\n",
    "print(f\"\\nsetting b[0,0] = 25\")\n",
    "\n",
    "b[0,0] = 25\n",
    "\n",
    "print(f\"b:\\n{b}\")\n",
    "print(f\"a:\\n{a}\")\n",
    "\n",
    "print(f\"\\nsetting a[-1,-1] = 25\")\n",
    "\n",
    "a[-1,-1] = 25\n",
    "\n",
    "print(f\"b:\\n{b}\")\n",
    "print(f\"a:\\n{a}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-insert",
   "metadata": {},
   "source": [
    "To tell whether a particular array is a view or a copy, we can check if the `base` attribute is set to something other than `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-wagner",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "print(f\"a: {a}\")\n",
    "\n",
    "b = a[:5]\n",
    "print(f\"b: {b}\")\n",
    "print(f\"b.base: {b.base}\")\n",
    "\n",
    "a = np.arange(16).reshape(4,4)\n",
    "\n",
    "print(f\"\\na:\\n{a}\")\n",
    "\n",
    "# adding a value to every element forces a copy\n",
    "b = a + 1 \n",
    "\n",
    "print(f\"b:\\n{b}\")\n",
    "print(f\"b.base: {b.base}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-parameter",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "\n",
    "To finalize the tutorial, I want to remind everybody that even though we're using a state-of-the-art piece of software, when we're dealing with real numbers [it is generally impossible to avoid precision errors](https://en.wikipedia.org/wiki/Floating-point_arithmetic). \n",
    "\n",
    "With this in mind, let's have a look at some of the main data types in NumPy, and why they are relevant to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-sunset",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = default_rng()\n",
    "integer_array = rng.integers(100, size=(3,3))\n",
    "\n",
    "print(f\"integer array:\\n{integer_array}\")\n",
    "\n",
    "float_array = rng.random(size=(3,3))\n",
    "\n",
    "print(f\"float array:\\n{float_array}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-census",
   "metadata": {},
   "source": [
    "We just created two arrays with different types, by default, both will use 64-bit representations, so we should get the same numbewr of bytes for each matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-matter",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"size of integer array: {integer_array.nbytes} bytes\")\n",
    "\n",
    "print(f\"size of float array: {float_array.nbytes} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-alberta",
   "metadata": {},
   "source": [
    "For such small matrices, this is quite trivial, but remember that things can grow very quikly and become quadratic very easily. For example, keeping track of connections in a social network of $N$ people will result in an array with shape $N \\times N$. If the links are not directed and there are no self-links, we can store all the data into a data buffer with $\\frac{N(N-1)}{2}$ items, still pretty large.\n",
    "\n",
    "Let's check how much memory we need to store a single graph if we use the defaults:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-survivor",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_graph_links_in_bits(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-dealer",
   "metadata": {},
   "source": [
    "It's apparent that we run out of memory rather quickly, considering that big data regularly operates on networks of several hundred thousands of nodes, it's pretty obvious we can't ignore this if we're serious about big data.\n",
    "\n",
    "Since our example is to store links, and we can do that using boolean values, let's see the same picture by moving to a smaller representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-discussion",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nbits = np.bool_(True).nbytes * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-addiction",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.arange(1000000)\n",
    "y = (x * (x-1) // 2) * (nbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-moldova",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-status",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_graph_links_in_bits(nbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24834da5-d0cd-468f-b3c2-1f3eedddc653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.arange(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd260c-5074-41a5-97c8-ed6da4181d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dce263-1f21-4b38-854e-a9326b47d4ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10), dpi=100)\n",
    "    \n",
    "x = np.arange(100000, dtype=np.float64)\n",
    "y = (x * (x-1) // 2) * (nbits)\n",
    "ax.plot(x, y, label=\"undirected\")\n",
    "\n",
    "# avg_lap = 6.4e+10\n",
    "# ax.axhline(y=avg_lap, color=\"green\", label=\"8GB (average laptop)\")\n",
    "# nnodes = np.argmin(np.abs(y - avg_lap))\n",
    "# ax.axvline(x=nnodes, color=\"green\", ls=\":\", label=f\"{nnodes:,} nodes\")\n",
    "\n",
    "# exp_lap = 2.56e+11\n",
    "# ax.axhline(y=exp_lap, color=\"orange\", label=\"64GB (expensive personal computer)\")\n",
    "# nnodes = np.argmin(np.abs(y - exp_lap))\n",
    "# ax.axvline(x=nnodes, color=\"orange\", ls=\":\", label=f\"{nnodes:,} nodes\")\n",
    "\n",
    "# server = 2.4e+12\n",
    "# ax.axhline(y=server, color=\"red\", label=\"300GB (dedicated server ~30USD+/day)\")\n",
    "# nnodes = np.argmin(np.abs(y - server))\n",
    "# ax.axvline(x=nnodes, color=\"red\", ls=\":\", label=f\"{nnodes:,} nodes\")\n",
    "\n",
    "ax.set_xlabel(\"nodes\")\n",
    "ax.set_ylabel(\"bits\")\n",
    "\n",
    "ax.set_title(f'Memory requirements using {nbits} bits')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-spray",
   "metadata": {},
   "source": [
    "Just with that simple change, we can now almost tripled the number of nodes that we can hold in memory (in a dense array)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
